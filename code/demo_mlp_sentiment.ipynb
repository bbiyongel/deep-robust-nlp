{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Sentence feature from a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from util import load_directory_data,load_dataset,download_and_load_datasets,gpusession\n",
    "from mlp_cls_class import mlp_cls_class\n",
    "print (\"Packages loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'movie_review'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : \"An album of songs so old everyone thinks they're new.\" This film has the elusive combination of pace and mood that set some films apart from the opening moments. And why not? Towering talent from Dame Judith Dench as a widow who plays saxaphone with a street musician to help him get the songs right, to Olympia Dukakis as the merry widow living in a Scottish castle on the alimony of her many marriages, to Ian Holm as the drummer who loved all the members of a World War II all girl (more or less) swing band. But wait, there's more. Add in Leslie Caron on bass, and the incomparable Clio Laine on lead vocal, at last, and the Blonde Bombshells are the hottest band in England since the Beatles. Well, OK, not really, but this movie is a winner.<br /><br />Elizabeth (Dench) spends the whole film trying to reunite the Blonde Bombshells to play at her granddaughter's school dance. And before you roll your eyes, imagine how difficult and courageous it would be for a bunch of sexegenarian women to step onstage in front of the Britney Spears generation following an act called \"Open Wound.\"<br /><br />In an age when actresses careers are over by the time they're 30, most bands' second album is a greatest hits compilation, and music more than a month old has almost no chance of airplay, it's great to see real talent, real music and a really good movie come from, where else, the BBC.<br /><br />I love this movie, and I know I'll watch it many more times, and enjoy it more each time. \n",
      "\n",
      "1 : this was one of the funniest and informative shows that I have ever seen. This is a MUST see for anyone over the age of 16. this show had me and my 2 boys laughing out loud from the beginning. I don't know if everything on the show was true but the way it was presented left little doubt that Mr Wuhl was not only very knowledgeable but he also had a blast presenting this information to the very lucky college kids who were in attendance. If Mr Wuhl ever decides to do this format again they will have to rent a building the size of the Georgia Dome to hold all the people who will want to see it. I agree with the idea of making this a HBO series. It would have an amazing following \n",
      "\n",
      "0 : 1\n",
      "1 : 1\n",
      "Shapes of 'x_train' and 'x_test' are (25000, 128) and (25000, 128).\n",
      "Shapes of 't_train' and 't_test' are (25000, 2) and (25000, 2).\n",
      "[data/movie_review.npz] Saved. Size is [26.4009]MB\n"
     ]
    }
   ],
   "source": [
    "savename = 'data/' + dataset_name + '.npz'\n",
    "FORCE_RELOAD = True \n",
    "if os.path.isfile(savename) & (~FORCE_RELOAD): # load if the file exists,\n",
    "    # Load \n",
    "    l = np.load(savename)    \n",
    "    x_train = l['x_train']\n",
    "    x_test = l['x_test']\n",
    "    t_train = l['t_train']\n",
    "    t_test = l['t_test']\n",
    "    print (\"[%s] Loaded. Size is [%.4f]MB\" % (savename,os.path.getsize(savename)/1000./1000.))\n",
    "else: # otherwise, make the data\n",
    "    # Download dataset\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR) # Reduce logging output.\n",
    "    train_df, test_df = download_and_load_datasets()\n",
    "    # Check dataset\n",
    "    for i in range(2):\n",
    "        print (i,':',train_df['sentence'][i],'\\n')\n",
    "    for i in range(2):\n",
    "        print (i,':',train_df['polarity'][i])\n",
    "    embed_module = hub.Module(\"https://tfhub.dev/google/nnlm-en-dim128/1\")\n",
    "    embed_train = embed_module(tf.reshape(train_df[\"sentence\"], shape=[-1]))\n",
    "    embed_test = embed_module(tf.reshape(test_df[\"sentence\"], shape=[-1]))\n",
    "    with tf.train.MonitoredTrainingSession(is_chief=True) as sess:\n",
    "        x_train = sess.run(embed_train)\n",
    "        x_test = sess.run(embed_test)\n",
    "    n_train,n_test = np.shape(x_train)[0],np.shape(x_test)[0]\n",
    "    t_train,t_test = np.zeros((n_train,2)),np.zeros((n_test,2))\n",
    "    for i in range(n_train):\n",
    "        t_train[i,train_df['polarity'][i]] = 1\n",
    "    for i in range(n_test):\n",
    "        t_test[i,test_df['polarity'][i]] = 1    \n",
    "    print(\"Shapes of 'x_train' and 'x_test' are %s and %s.\"%\n",
    "          (x_train.shape,x_test.shape)) # (result: (1, 128))    \n",
    "    print(\"Shapes of 't_train' and 't_test' are %s and %s.\"%\n",
    "          (t_train.shape,t_test.shape)) # (result: (1, 128))    \n",
    "    # Save \n",
    "    np.savez(savename,x_train=x_train,x_test=x_test,t_train=t_train,t_test=t_test)\n",
    "    print (\"[%s] Saved. Size is [%.4f]MB\" % (savename,os.path.getsize(savename)/1000./1000.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Global Variables ====\n",
      " [00] Name:[mlp_cls_sentiment/lin0/weights:0] Shape:[[128, 128]]\n",
      " [01] Name:[mlp_cls_sentiment/lin0/BatchNorm/beta:0] Shape:[[128]]\n",
      " [02] Name:[mlp_cls_sentiment/lin0/BatchNorm/moving_mean:0] Shape:[[128]]\n",
      " [03] Name:[mlp_cls_sentiment/lin0/BatchNorm/moving_variance:0] Shape:[[128]]\n",
      " [04] Name:[mlp_cls_sentiment/lin1/weights:0] Shape:[[128, 64]]\n",
      " [05] Name:[mlp_cls_sentiment/lin1/BatchNorm/beta:0] Shape:[[64]]\n",
      " [06] Name:[mlp_cls_sentiment/lin1/BatchNorm/moving_mean:0] Shape:[[64]]\n",
      " [07] Name:[mlp_cls_sentiment/lin1/BatchNorm/moving_variance:0] Shape:[[64]]\n",
      " [08] Name:[mlp_cls_sentiment/out/weights:0] Shape:[[64, 2]]\n",
      " [09] Name:[mlp_cls_sentiment/out/biases:0] Shape:[[2]]\n",
      " [10] Name:[mlp_cls_sentiment/lin0/weights/Adam:0] Shape:[[128, 128]]\n",
      " [11] Name:[mlp_cls_sentiment/lin0/weights/Adam_1:0] Shape:[[128, 128]]\n",
      " [12] Name:[mlp_cls_sentiment/lin0/BatchNorm/beta/Adam:0] Shape:[[128]]\n",
      " [13] Name:[mlp_cls_sentiment/lin0/BatchNorm/beta/Adam_1:0] Shape:[[128]]\n",
      " [14] Name:[mlp_cls_sentiment/lin1/weights/Adam:0] Shape:[[128, 64]]\n",
      " [15] Name:[mlp_cls_sentiment/lin1/weights/Adam_1:0] Shape:[[128, 64]]\n",
      " [16] Name:[mlp_cls_sentiment/lin1/BatchNorm/beta/Adam:0] Shape:[[64]]\n",
      " [17] Name:[mlp_cls_sentiment/lin1/BatchNorm/beta/Adam_1:0] Shape:[[64]]\n",
      " [18] Name:[mlp_cls_sentiment/out/weights/Adam:0] Shape:[[64, 2]]\n",
      " [19] Name:[mlp_cls_sentiment/out/weights/Adam_1:0] Shape:[[64, 2]]\n",
      " [20] Name:[mlp_cls_sentiment/out/biases/Adam:0] Shape:[[2]]\n",
      " [21] Name:[mlp_cls_sentiment/out/biases/Adam_1:0] Shape:[[2]]\n",
      "Text name: res/res_mlp_cls_sentiment.txt\n",
      "[00/5] [Loss] train:0.478 test:0.493 [Accr] train:77.1% test:76.3% maxTest:76.3%\n",
      "[01/5] [Loss] train:0.410 test:0.434 [Accr] train:81.5% test:79.4% maxTest:79.4%\n",
      "[02/5] [Loss] train:0.445 test:0.477 [Accr] train:78.3% test:76.5% maxTest:79.4%\n",
      "[03/5] [Loss] train:0.384 test:0.435 [Accr] train:82.5% test:79.7% maxTest:79.7%\n",
      "[04/5] [Loss] train:0.375 test:0.437 [Accr] train:83.3% test:79.8% maxTest:79.8%\n",
      "[05/5] [Loss] train:0.464 test:0.539 [Accr] train:78.7% test:75.6% maxTest:79.8%\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph(); tf.set_random_seed(0)\n",
    "CNN = mlp_cls_class(_name='mlp_cls_sentiment',_x_dim=128,_t_dim=2,_h_dims=[128,64],\n",
    "                _actv=tf.nn.relu,_bn=slim.batch_norm,_l2_reg_coef=1e-5,_momentum=0.5,\n",
    "                _USE_SGD=False,_USE_MIXUP=False,_GPU_ID=0,_VERBOSE=True)\n",
    "sess = gpusession();sess.run(tf.global_variables_initializer()) \n",
    "CNN.train(sess,_x_train=x_train,_t_train=t_train,_x_test=x_test,_t_test=t_test,\n",
    "              _max_epoch=10,_batch_size=128,_lr=1e-3,_kp=0.9,\n",
    "              _LR_SCHEDULE=False,_PRINT_EVERY=10,_VERBOSE_TRAIN=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
